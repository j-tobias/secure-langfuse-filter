# Privacy Model

This document describes the filter's approach to anonymising usage telemetry before it leaves the OpenWebUI server. The core principle: **collect operational metrics without collecting anything that identifies a specific user or reveals conversation content**.

---

## What Is Sent to Langfuse

| Data | Example | Purpose |
|------|---------|---------|
| Hashed user ID | `a1b2c3d4e5f6...` (64 hex chars) | Correlate usage across sessions without knowing who the user is |
| Chat ID | `abc-123-def` | Group messages into conversations |
| Model ID / name | `llama3.1:latest` | Track model usage |
| Token counts | `{input: 45, output: 28}` | Monitor resource consumption |
| Response time | `1234.5` ms | Performance monitoring |
| Message stats | `{message_count: 3, roles: [...], input_chars: 480, estimated_input_tokens: 120}` | Understand message structure/size without seeing content |
| Tags | `["open-webui", "title_generation"]` | Categorise trace types |
| Chat title | `"Math Questions"` | Browsable trace names *(see note below)* |
| Chat tags | `"math, arithmetic"` | Topic classification *(see note below)* |
| Sanitised metadata | `{model_id, interface, ...}` | Operational context |

> **Note on title/tags**: Chat titles and tags are generated by the LLM and may indirectly hint at conversation topics. They never contain user-identifiable information (names, emails, etc.), but they do reveal the subject matter. If even topic visibility is a concern, disable the `insert_tags` valve or remove the enrichment capture in outlet.

---

## What Is Never Sent

| Data | Where it exists | How it's blocked |
|------|----------------|-----------------|
| User email | `body.metadata.user.email`, `user["email"]` | Hashed via SHA-256 before use |
| User name | `body.metadata.user.name`, `user["name"]` | Stripped by `_sanitize_metadata()` |
| Display name | `metadata.user.display_name` | Stripped by `_sanitize_metadata()` |
| Avatar URL | `metadata.user.profile_image_url` | Stripped by `_sanitize_metadata()` |
| User location | `metadata.variables.{{USER_LOCATION}}` | Stripped by `_is_pii_variable()` |
| Message content | `body.messages[].content` | **Never sent** — only `len()` and word counts are computed; the text itself is discarded |
| Image data | `content[].image_url.url` | Never sent — only text-type parts are measured for char/word counts |
| Raw user object | `body.user`, `user` param | Never forwarded; only `_hash_user_id(email)` is used |

---

## Sanitisation Layers

The filter applies **three layers** of sanitisation, each addressing a different attack surface:

### Layer 1 — User Identity Hashing

```python
@staticmethod
def _hash_user_id(user_email: Optional[str]) -> Optional[str]:
    if not user_email:
        return None
    return hashlib.sha256(user_email.lower().strip().encode("utf-8")).hexdigest()
```

- **Input**: `"Alice@Example.com"`
- **Output**: `"2c7a1e5f..."` (64-char hex string)
- Normalised (lowered, stripped) before hashing for consistency
- SHA-256 is a one-way function — the email cannot be recovered from the hash
- The same email always produces the same hash, enabling cross-session correlation without identity exposure

### Layer 2 — Metadata PII Stripping

Operates on the `metadata` dict from `body.metadata`. Two mechanisms:

#### Exact key matching (top-level)

```python
_PII_KEYS = {
    "user", "name", "email", "user_email", "user_name",
    "profile_image_url", "avatar", "display_name", "user_id",
}
```

Any top-level key in metadata whose lowercased name matches this set is **removed entirely**.

#### Substring pattern matching (variables dict)

```python
_PII_PATTERNS = {
    "user", "name", "email", "avatar", "location",
    "profile", "display", "phone", "address", "ip",
}
```

Applied to keys in `metadata.variables` (OpenWebUI template variables like `{{USER_NAME}}`, `{{USER_LOCATION}}`). A key is removed if **any** pattern appears as a substring in the lowercased key name.

Example:
```
metadata.variables = {
    "{{USER_NAME}}": "Alice",         ← removed ("user" + "name" match)
    "{{USER_LOCATION}}": "Berlin",    ← removed ("user" + "location" match)
    "{{CURRENT_DATE}}": "2025-01-15", ← kept (no PII pattern)
    "{{USER_LANGUAGE}}": "en-US",     ← removed ("user" match)
}
```

### Layer 3 — Content Exclusion

**No message content is ever sent to Langfuse.** The filter reads message content only to compute aggregate statistics:

```python
@staticmethod
def _message_stats(messages: list) -> dict:
    # Reads content ONLY for len() — text is never stored
    return {
        "message_count": len(messages),
        "roles": roles,
        "input_chars": total_chars,
        "estimated_input_tokens": max(1, total_chars // 4),
    }
```

This is fundamentally different from redaction (replacing text with `[REDACTED | ...]`). With content exclusion, the body is never copied, body content is never serialised, and no text — redacted or otherwise — appears anywhere in Langfuse.

---

## Body Immutability

A critical design constraint: **the filter never mutates the `body` dict**.

1. **Reads** from `body` and `body.metadata` to extract operational data
2. Computes **summary dicts** (counts, roles, tokens) from messages — no text stored
3. Returns the **original, unmodified** `body` to OpenWebUI

This ensures the filter is invisible to the rest of the pipeline.

---

## Threat Model

| Threat | Mitigation |
|--------|-----------|
| Langfuse admin sees user emails | Emails are SHA-256 hashed; only the hash is stored |
| Langfuse data breach exposes conversations | No message content is sent — only counts and metadata |
| Metadata contains user PII | 2 sanitisation layers strip known PII keys |
| New metadata keys contain PII | Substring matching catches keys containing `user`, `name`, `email`, etc. |
| Filter modifies request and breaks OpenWebUI | Body is never mutated; summary dicts computed separately |
| Long-running server accumulates user data in memory | TTL-based cleanup evicts state after 24 hours of inactivity |

### Known Limitations

1. **Chat titles and tags** are forwarded as-is. If the LLM generates a title like "Alice's tax questions", this is visible in Langfuse. The user can disable enrichment capture if this is a concern.
2. **Token heuristic** (`len(text) // 4`) is approximate. Actual token counts from the model are used when available; the heuristic only appears in message summaries.
3. **SHA-256 without salt** means the same email always maps to the same hash. An attacker with a list of candidate emails could hash them to find matches. For most use cases this is acceptable; add a secret salt to `_hash_user_id()` if your threat model requires it.
4. **Model names** are sent in full. If your model names contain sensitive information (e.g., custom fine-tune names with client identifiers), consider scrubbing them.
