# Privacy Model

This document describes the filter's approach to anonymising usage telemetry before it leaves the OpenWebUI server. The core principle: **collect operational metrics without collecting anything that identifies a specific user or reveals conversation content**.

---

## What Is Sent to Langfuse

| Data | Example | Purpose |
|------|---------|---------|
| Hashed user ID | `a1b2c3d4e5f6...` (64 hex chars) | Correlate usage across sessions without knowing who the user is |
| Chat ID | `abc-123-def` | Group messages into conversations |
| Model ID / name | `llama3.1:latest` | Track model usage |
| Token counts | `{input: 45, output: 28}` | Monitor resource consumption |
| Response time | `1234.5` ms | Performance monitoring |
| Content summaries | `[REDACTED \| 523 chars \| 98 words \| ~131 tokens]` | Understand message size without seeing content |
| Tags | `["open-webui", "title_generation"]` | Categorise trace types |
| Chat title | `"Math Questions"` | Browsable trace names *(see note below)* |
| Chat tags | `"math, arithmetic"` | Topic classification *(see note below)* |
| Sanitised metadata | `{model_id, interface, ...}` | Operational context |

> **Note on title/tags**: Chat titles and tags are generated by the LLM and may indirectly hint at conversation topics. They never contain user-identifiable information (names, emails, etc.), but they do reveal the subject matter. If even topic visibility is a concern, disable the `insert_tags` valve or remove the enrichment capture in outlet.

---

## What Is Never Sent

| Data | Where it exists | How it's blocked |
|------|----------------|-----------------|
| User email | `body.metadata.user.email`, `user["email"]` | Hashed via SHA-256 before use |
| User name | `body.metadata.user.name`, `user["name"]` | Stripped by `_sanitize_metadata()` |
| Display name | `metadata.user.display_name` | Stripped by `_sanitize_metadata()` |
| Avatar URL | `metadata.user.profile_image_url` | Stripped by `_sanitize_metadata()` |
| User location | `metadata.variables.{{USER_LOCATION}}` | Stripped by `_is_pii_variable()` |
| Message content | `body.messages[].content` | Replaced by `_redact_text()` summary |
| Image data | `content[].image_url.url` | Replaced with `[REDACTED image]` |
| Raw user object | `body.user`, `user` param | Never forwarded; only `_hash_user_id(email)` is used |

---

## Sanitisation Layers

The filter applies **five layers** of sanitisation, each addressing a different attack surface:

### Layer 1 — User Identity Hashing

```python
@staticmethod
def _hash_user_id(user_email: Optional[str]) -> Optional[str]:
    if not user_email:
        return None
    return hashlib.sha256(user_email.lower().strip().encode("utf-8")).hexdigest()
```

- **Input**: `"Alice@Example.com"`
- **Output**: `"2c7a1e5f..."` (64-char hex string)
- Normalised (lowered, stripped) before hashing for consistency
- SHA-256 is a one-way function — the email cannot be recovered from the hash
- The same email always produces the same hash, enabling cross-session correlation without identity exposure

### Layer 2 — Metadata PII Stripping

Operates on the `metadata` dict from `body.metadata`. Two mechanisms:

#### Exact key matching (top-level)

```python
_PII_KEYS = {
    "user", "name", "email", "user_email", "user_name",
    "profile_image_url", "avatar", "display_name", "user_id",
}
```

Any top-level key in metadata whose lowercased name matches this set is **removed entirely**.

#### Substring pattern matching (variables dict)

```python
_PII_PATTERNS = {
    "user", "name", "email", "avatar", "location",
    "profile", "display", "phone", "address", "ip",
}
```

Applied to keys in `metadata.variables` (OpenWebUI template variables like `{{USER_NAME}}`, `{{USER_LOCATION}}`). A key is removed if **any** pattern appears as a substring in the lowercased key name.

Example:
```
metadata.variables = {
    "{{USER_NAME}}": "Alice",         ← removed ("user" + "name" match)
    "{{USER_LOCATION}}": "Berlin",    ← removed ("user" + "location" match)
    "{{CURRENT_DATE}}": "2025-01-15", ← kept (no PII pattern)
    "{{USER_LANGUAGE}}": "en-US",     ← removed ("user" match)
}
```

### Layer 3 — Body PII Stripping

Operates on the top-level `body` dict. Same approach as Layer 2's exact matching but applied to body keys:

```python
_sanitize_body_pii_keys = {
    "user", "user_id", "user_email", "user_name",
    "name", "email", "profile_image_url", "avatar",
}
```

This catches any user-identifiable fields that OpenWebUI places directly in the body (not nested in metadata).

### Layer 4 — Content Redaction

When `redact_content=True` (default), all message text is replaced with a metadata summary:

```
"What is the capital of France?" → "[REDACTED | 32 chars | 7 words | ~8 tokens]"
```

Handles three content formats:

| Format | Example | Redaction |
|--------|---------|-----------|
| Plain text | `"content": "Hello"` | `"content": "[REDACTED \| 5 chars \| 1 words \| ~1 tokens]"` |
| Multi-modal list | `[{"type": "text", "text": "..."}, {"type": "image_url", ...}]` | Text parts redacted, image URLs replaced with `[REDACTED image]` |
| Other | Any non-string, non-list content | Cast to string, then redacted |

Structural metadata is always preserved: `role`, `tool_calls`, `name` (function names in tool calls, not user names).

### Layer 5 — Debug Log Sanitisation

Even debug logs are sanitised. The outlet function logs only:

```python
self.log(f"Outlet called for chat_id={chat_id}, model={model_id}, messages={len(messages)}")
```

**Not** the full body, which would leak message content into server logs.

---

## Body Immutability

A critical design constraint: **the filter never mutates the `body` dict**.

Earlier versions wrote sanitised data back into `body.metadata`, which caused OpenWebUI errors (e.g., overwriting `chat_id` broke session matching). The current design:

1. **Reads** from `body` and `body.metadata` to extract operational data
2. Creates **separate copies** (`safe_metadata`, `safe_body`) for Langfuse
3. Returns the **original, unmodified** `body` to OpenWebUI

This ensures the filter is invisible to the rest of the pipeline.

---

## Threat Model

| Threat | Mitigation |
|--------|-----------|
| Langfuse admin sees user emails | Emails are SHA-256 hashed; only the hash is stored |
| Langfuse data breach exposes conversations | Content is redacted; only size summaries are stored |
| Metadata contains user PII | 3 sanitisation layers strip known PII keys |
| New metadata keys contain PII | Substring matching catches keys containing `user`, `name`, `email`, etc. |
| Debug logs leak content | Outlet logs only chat_id, model, and message count |
| Filter modifies request and breaks OpenWebUI | Body is never mutated; separate copies used for Langfuse |
| Long-running server accumulates user data in memory | TTL-based cleanup evicts state after 24 hours of inactivity |

### Known Limitations

1. **Chat titles and tags** are forwarded as-is. If the LLM generates a title like "Alice's tax questions", this is visible in Langfuse. The user can disable enrichment capture if this is a concern.
2. **Token heuristic** (`len(text) // 4`) is approximate. Actual token counts from the model are used when available; the heuristic only appears in redaction summaries.
3. **SHA-256 without salt** means the same email always maps to the same hash. An attacker with a list of candidate emails could hash them to find matches. For most use cases this is acceptable; add a secret salt to `_hash_user_id()` if your threat model requires it.
4. **Model names** are sent in full. If your model names contain sensitive information (e.g., custom fine-tune names with client identifiers), consider scrubbing them.
